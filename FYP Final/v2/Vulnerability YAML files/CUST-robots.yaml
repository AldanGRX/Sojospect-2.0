id: CUST-robots
name: "Lack of Robots.txt"
description: "robots.txt is a necessary standard used by websites to communicate with web crawlers and other automated agents (like search engine bots) about which parts of the site should not be crawled or scraped."
severity: Low
affected_versions: []
solution: "It is recommended to include the robots.txt file in the webroot."
references: []
additional_information_check: False